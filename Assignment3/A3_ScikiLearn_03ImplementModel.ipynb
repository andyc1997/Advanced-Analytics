{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 3\n",
    "\n",
    "\n",
    "### Goals\n",
    "\n",
    "- First: the original hashtags have been blanked out from the tweet. Build a predictive model that can predict the hashtag used based on the rest of the tweet text\n",
    "- Second: show that your model can make predictions in a deployed streaming setting using Spark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import string\n",
    "import spacy\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from sklearn.pipeline import Pipeline\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/amgiraldov/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_stemmer = SnowballStemmer('english')\n",
    "nlp = spacy.load('es_core_news_sm')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "punctuation = set(string.punctuation)\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/amgiraldov/OneDrive - KU Leuven/Advanced Analytics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize1(text):\n",
    "    doc = nlp(text)\n",
    "    words = [t.orth_ for t in doc if not t.is_punct | t.is_stop]\n",
    "    lexical_tokens = [t.lower() for t in words if t.isalpha()]\n",
    "    return lexical_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def applyMLClassification(fileVectorizer, fileModel, sentence):\n",
    "    sentence = [sentence]\n",
    "    vectorizer = joblib.load(fileVectorizer)\n",
    "    classifier = joblib.load(fileModel)\n",
    "    test_X = vectorizer.transform(sentence)\n",
    "    predict = classifier.predict(test_X)\n",
    "    return predict\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['#vaccine'], dtype='<U14')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "applyMLClassification(\"vectorizer.joblib\", \"classifier.joblib\",\n",
    "                     \"Alright im going for my first vaccine shot guys wish me luck!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['#covid'], dtype='<U14')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "applyMLClassification(\"vectorizer.joblib\", \n",
    "                      \"classifier.joblib\",\"An important discovery by detective jsdfposjpqyuee1 It indicates that Chao Shan was the leader of the group testing  on Rhesus Macaque monkeys and, given how early the results were published, those experiments might have begun before the pandemic began. \")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
