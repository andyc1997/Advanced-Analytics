{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 3 - Preprocessing data\n",
    "\n",
    "\n",
    "### Goals\n",
    "\n",
    "- First: the original hashtags have been blanked out from the tweet. Build a predictive model that can predict the hashtag used based on the rest of the tweet text\n",
    "- Second: show that your model can make predictions in a deployed streaming setting using Spark\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tasks\n",
    "Using Spark, your task for this assignment is as follows:\n",
    "\n",
    "- [X] Construct a historical data set using the provided stream\n",
    "- [ ] Construct a predictive model to predict the used hashtag based on the tweet text\n",
    "     - [X] load historical data \n",
    "     - [X] set histdata (.json) as dataframe\n",
    "     - [ ]  \n",
    "- [ ] Use your trained model to show you can make predictions as the stream comes in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The stream is text-based with each line containing one tweet (one instance) formatted as a JSON dictionary with the following keys (features): \"tweet_id\" (id of the tweet, not to be used), \"tweet_text\" (the tweet with the hashtags blanked out) and \"label\" (the target) You can use extra data and libraries if you want, but this is not required You are strongly encouraged to build your model using spark.ml (MLlib), but you can use scikit-learn as a fallback if things don't work out\n",
    "I.e. show that you can connect to the data source, preprocess/featurize incoming tweets, have your model predict the label, and show it, similar to \"spark_streaming_example_predicting.py.ipynb\" (but hopefully using a smarter, real predictive model) This means that you'll need to look for a way to save and load your trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://LAPTOP-PJSVL4LK:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=PySparkShell>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import glob\n",
    "#print(len(glob.glob(\"C:/Users/Marce/OneDrive - KU Leuven/Advanced Analytics/myoutput_draft/-*\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data\n",
    "\n",
    "What a nightmare!!\n",
    "\n",
    "sc.textFile along with spark.read.json collapse with the amount of tweets collected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = sc.textFile(\"C:/Users/Marce/OneDrive - KU Leuven/Advanced Analytics/myoutput_draft/-*\",minPartitions=8 )\n",
    "#data.first() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = spark.read.json(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we have to get all the files that were collected. Then, we filter only for the ones that have tweet info (files that do not include _SUCCESS or crc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_path = \"C:/Users/Marce/OneDrive - KU Leuven/Advanced Analytics\"\n",
    "files=[]\n",
    "\n",
    "for (dirpath, dirnames, filenames) in os.walk(parent_path):\n",
    "    files.extend(os.path.join(dirpath, filename) for filename in filenames)\n",
    "\n",
    "files_filter=[]\n",
    "\n",
    "for ad in files: \n",
    "    if not \"_SUCCESS\" in ad and not \"crc\" in ad and not \".csv\" in ad:\n",
    "        files_filter.append(ad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(files_filter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update: Colapsed at 274. why? loop was using \n",
    "colapsed by me at 775"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df1 = spark.read.json(files_filter[0])\n",
    "\n",
    "i = 1\n",
    "while i < len(files_filter):\n",
    "  # create the csv writer object\n",
    "    for dirpath in files_filter[i:i+1]:\n",
    "        file=spark.read.json(dirpath)\n",
    "        try:\n",
    "            df3 = file.toPandas()\n",
    "        #    df1=df1.union(file)         \n",
    "        except TypeError:\n",
    "            pass   \n",
    "    df3.to_csv(\"C:/Users/Marce/OneDrive - KU Leuven/Advanced Analytics/tweet_05.csv\", mode= 'a', index= False, header = False)\n",
    "    i += 1\n",
    "    print(i, \"has been read\")\n",
    "else:\n",
    "    print(\"I'm done!! (in theory)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:/Users/Marce/OneDrive - KU Leuven/Advanced Analytics\\\\tweet_.csv',\n",
       " 'C:/Users/Marce/OneDrive - KU Leuven/Advanced Analytics\\\\tweet_00.csv',\n",
       " 'C:/Users/Marce/OneDrive - KU Leuven/Advanced Analytics\\\\tweet_01.csv',\n",
       " 'C:/Users/Marce/OneDrive - KU Leuven/Advanced Analytics\\\\tweet_02.csv',\n",
       " 'C:/Users/Marce/OneDrive - KU Leuven/Advanced Analytics\\\\tweet_03.csv',\n",
       " 'C:/Users/Marce/OneDrive - KU Leuven/Advanced Analytics\\\\tweet_04.csv',\n",
       " 'C:/Users/Marce/OneDrive - KU Leuven/Advanced Analytics\\\\tweet_05.csv']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11051</th>\n",
       "      <td>#inflation</td>\n",
       "      <td>1385683130338643968</td>\n",
       "      <td>Happy Friday! Today Chat chats inflation - we'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3906</th>\n",
       "      <td>#vaccine</td>\n",
       "      <td>1382328808066281473</td>\n",
       "      <td>EMA is working closely with the @US_FDA and ot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2129</th>\n",
       "      <td>#china</td>\n",
       "      <td>1382010563392282624</td>\n",
       "      <td>@DrTedros and #███████ just destroyed our live...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1218</th>\n",
       "      <td>#biden</td>\n",
       "      <td>1381664559711277062</td>\n",
       "      <td>@AntifascistSec @7News Lol. Do your parents kn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6967</th>\n",
       "      <td>#china</td>\n",
       "      <td>1382738195847155713</td>\n",
       "      <td>'You Have The AUDACITY To Talk About #███████?...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            label             tweet_id  \\\n",
       "11051  #inflation  1385683130338643968   \n",
       "3906     #vaccine  1382328808066281473   \n",
       "2129       #china  1382010563392282624   \n",
       "1218       #biden  1381664559711277062   \n",
       "6967       #china  1382738195847155713   \n",
       "\n",
       "                                              tweet_text  \n",
       "11051  Happy Friday! Today Chat chats inflation - we'...  \n",
       "3906   EMA is working closely with the @US_FDA and ot...  \n",
       "2129   @DrTedros and #███████ just destroyed our live...  \n",
       "1218   @AntifascistSec @7News Lol. Do your parents kn...  \n",
       "6967   'You Have The AUDACITY To Talk About #███████?...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11577, 3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
