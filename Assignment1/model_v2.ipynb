{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.compose import ColumnTransformer \n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from imblearn.pipeline import Pipeline, make_pipeline\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print more rows and columns of pandas.DataFrame\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **<font color='green'>Version of some libraries</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.24.1'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I am using the lateset sklearn version\n",
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.8.0'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import imblearn\n",
    "imblearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.4.1'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost\n",
    "xgboost.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change path if needed\n",
    "path = r'C:\\Users\\user\\Desktop\\KUL - Mstat\\Big Data Platforms and Technologies\\project'\n",
    "data = pd.read_csv(path + r'\\ctrain.csv')\n",
    "data_test = pd.read_csv(path + r'\\ctest.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **<font color='blue'>Some transformations</font>**\n",
    "- <font color='blue'>Some transformations are not made at the stage of data cleaning for the sake of exploratory data analysis. Hence, they are done in this section.</font>\n",
    "- <font color='blue'>They are mainly age-related variables.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weight of evidence & Information value\n",
    "def get_information_value(data, features):\n",
    "    # cross tab\n",
    "    tab = pd.crosstab(data[features], data['fraud'])\n",
    "    # weight of evidence\n",
    "    tab['all'] = tab[['Y', 'N']].sum(axis = 1) \n",
    "    tab['share'] = tab['all'] / tab['all'].sum(axis = 0)\n",
    "    tab['Y_rate'] = tab['Y'] / tab['all']\n",
    "    tab['N_dist'] = tab['N'] / tab['N'].sum()\n",
    "    tab['Y_dist'] = tab['Y'] / tab['Y'].sum()\n",
    "    tab['WoE'] = np.log(tab['N_dist'] / tab['Y_dist'])\n",
    "    tab = tab.replace({'WoE': {np.inf: 0, -np.inf: 0}})\n",
    "    # information value\n",
    "    tab['IV'] = tab['WoE'] * (tab['N_dist'] - tab['Y_dist'])\n",
    "    return tab[np.abs(tab['IV']) > 0.01].index.values # threshold 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py:679: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# apply get_information_value\n",
    "claim_postal_code_list = get_information_value(data, 'claim_postal_code')\n",
    "policy_holder_postal_code_list = get_information_value(data, 'policy_holder_postal_code')\n",
    "driver_postal_code_list = get_information_value(data, 'driver_postal_code')\n",
    "third_party_1_postal_code_list = get_information_value(data, 'third_party_1_postal_code')\n",
    "third_party_2_postal_code_list = get_information_value(data, 'third_party_2_postal_code')\n",
    "repair_postal_code_list = get_information_value(data, 'repair_postal_code')\n",
    "claim_vehicle_brand_list = get_information_value(data, 'claim_vehicle_brand')\n",
    "policy_coverage_type_list = get_information_value(data, 'policy_coverage_type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_age(value):\n",
    "    # A simple program to discretize age\n",
    "    if pd.isna(value):\n",
    "        return 'unknown'\n",
    "    else:\n",
    "        if value <= 20:\n",
    "            return '<=20'\n",
    "#        elif value <= 30:\n",
    "#            return '<=30'\n",
    "        elif value <= 40:\n",
    "            return '<=40'\n",
    "#        elif value <= 50:\n",
    "#            return '<=50'\n",
    "        elif value <= 60:\n",
    "            return '<=60'\n",
    " #       elif value <= 70:\n",
    " #           return '<=70'\n",
    "        elif value <= 80:\n",
    "            return '<=80'\n",
    "        else:\n",
    "            return '>80'\n",
    "\n",
    "def handle_policy_coverage(value):\n",
    "    # A simple program to discretize policy_coverage_1000\n",
    "    if pd.isna(value):\n",
    "        return 'unknown'\n",
    "    else:\n",
    "        if value <= 20:\n",
    "            return '<=20'\n",
    "        elif value <= 40:\n",
    "            return '<=40'\n",
    "        elif value <= 60:\n",
    "            return '<=60'\n",
    "        elif value <= 80:\n",
    "            return '<=80'\n",
    "        else:\n",
    "            return '>80'\n",
    "\n",
    "def handle_categorical_grouping(value, grouping_list):\n",
    "        if value == 'unknown':\n",
    "            return value\n",
    "        elif value in grouping_list:\n",
    "            return str(value)\n",
    "        else:\n",
    "            return 'other'\n",
    "        \n",
    "def transform(x_dataset):\n",
    "        x_dataset['driver_age'] = x_dataset['driver_age'].apply(lambda x: handle_age(x))\n",
    "        x_dataset['policy_holder_age'] = x_dataset['policy_holder_age'].apply(lambda x: handle_age(x))\n",
    "        x_dataset['repair_age'] = x_dataset['repair_age'].apply(lambda x: handle_age(x))\n",
    "        x_dataset['third_party_1_age'] = x_dataset['third_party_1_age'].apply(lambda x: handle_age(x))\n",
    "        x_dataset['third_party_2_age'] = x_dataset['third_party_2_age'].apply(lambda x: handle_age(x))\n",
    "        x_dataset['third_party_3_age'] = x_dataset['third_party_3_age'].apply(lambda x: handle_age(x))\n",
    "        \n",
    "        x_dataset['policy_coverage_1000'] = x_dataset['policy_coverage_1000'].apply(lambda x: handle_policy_coverage(x))\n",
    "        \n",
    "        x_dataset['claim_postal_code'] = x_dataset['claim_postal_code'].apply(lambda x: handle_categorical_grouping(x, claim_postal_code_list))\n",
    "        x_dataset['policy_holder_postal_code'] = x_dataset['policy_holder_postal_code'].apply(lambda x: handle_categorical_grouping(x, policy_holder_postal_code_list))\n",
    "        x_dataset['driver_postal_code'] = x_dataset['driver_postal_code'].apply(lambda x: handle_categorical_grouping(x, driver_postal_code_list))\n",
    "        x_dataset['third_party_1_postal_code'] = x_dataset['third_party_1_postal_code'].apply(lambda x: handle_categorical_grouping(x, third_party_1_postal_code_list))\n",
    "        x_dataset['third_party_2_postal_code'] = x_dataset['third_party_2_postal_code'].apply(lambda x: handle_categorical_grouping(x, third_party_2_postal_code_list))\n",
    "        x_dataset['third_party_3_postal_code'] = x_dataset['third_party_3_postal_code'].apply(lambda x: x if x == 'unknown' else 'other')\n",
    "        x_dataset['repair_postal_code'] = x_dataset['repair_postal_code'].apply(lambda x: handle_categorical_grouping(x, repair_postal_code_list))\n",
    "        # x_dataset['claim_vehicle_brand'] = x_dataset['claim_vehicle_brand'].apply(lambda x: handle_categorical_grouping(x, claim_vehicle_brand_list))\n",
    "        x_dataset['policy_coverage_type'] = x_dataset['policy_coverage_type'].apply(lambda x: handle_categorical_grouping(x, policy_coverage_type_list))        \n",
    "        \n",
    "        return x_dataset.drop(['third_party_1_id_known', 'third_party_2_id_known', 'third_party_3_id_known'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'claim_amount', 'fraud'}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Some transformation\n",
    "data = transform(data)\n",
    "data_test = transform(data_test)\n",
    "\n",
    "# Sanity check: fraud, claim_amount only\n",
    "set(data.columns) - set(data_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset\n",
    "X, y = pd.get_dummies(data.drop(['claim_id', 'fraud'], axis = 1), drop_first = True), data['fraud'].apply(lambda x: 1 if x == 'Y' else 0)\n",
    "X_test = pd.get_dummies(data_test.drop(['claim_id'], axis = 1))\n",
    "cv = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **<font color='blue'>Random forest model with cross validation</font>**\n",
    "- <font color='blue'>Based on the results of cross validation, it is found that kNN = 7 for SMOTE, 500 trees and 90 number of features are the best hyperparameters in terms of weighted precision.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'k_neighbors': 3, 'max_features': 10, 'n_estimators': 200, 'cv_precision_score': 0.8372879472890933, 'cv_recall_score': 0.3072769942449564, 'sum_top100': 695579.64}\n",
      "0.0625\n",
      "{'k_neighbors': 3, 'max_features': 30, 'n_estimators': 200, 'cv_precision_score': 0.8413509369209983, 'cv_recall_score': 0.3302931544874211, 'sum_top100': 705090.85}\n",
      "0.125\n",
      "{'k_neighbors': 3, 'max_features': 50, 'n_estimators': 200, 'cv_precision_score': 0.818573724296256, 'cv_recall_score': 0.3031683008388451, 'sum_top100': 678342.48}\n",
      "0.1875\n",
      "{'k_neighbors': 3, 'max_features': 70, 'n_estimators': 200, 'cv_precision_score': 0.8177762450494497, 'cv_recall_score': 0.304540936321018, 'sum_top100': 658331.3300000001}\n",
      "0.25\n",
      "{'k_neighbors': 5, 'max_features': 10, 'n_estimators': 200, 'cv_precision_score': 0.8172075563503786, 'cv_recall_score': 0.29325611315768085, 'sum_top100': 650263.64}\n",
      "0.3125\n",
      "{'k_neighbors': 5, 'max_features': 30, 'n_estimators': 200, 'cv_precision_score': 0.8215184876117986, 'cv_recall_score': 0.3241634272527578, 'sum_top100': 714458.14}\n",
      "0.375\n",
      "{'k_neighbors': 5, 'max_features': 50, 'n_estimators': 200, 'cv_precision_score': 0.807844892597258, 'cv_recall_score': 0.3085730867764779, 'sum_top100': 682416.48}\n",
      "0.4375\n",
      "{'k_neighbors': 5, 'max_features': 70, 'n_estimators': 200, 'cv_precision_score': 0.8174732988824285, 'cv_recall_score': 0.28124958577134684, 'sum_top100': 645136.3300000001}\n",
      "0.5\n",
      "{'k_neighbors': 7, 'max_features': 10, 'n_estimators': 200, 'cv_precision_score': 0.8577588824887311, 'cv_recall_score': 0.31609026893718295, 'sum_top100': 669948.32}\n",
      "0.5625\n",
      "{'k_neighbors': 7, 'max_features': 30, 'n_estimators': 200, 'cv_precision_score': 0.830208562103248, 'cv_recall_score': 0.3288299802036464, 'sum_top100': 712911.94}\n",
      "0.625\n",
      "{'k_neighbors': 7, 'max_features': 50, 'n_estimators': 200, 'cv_precision_score': 0.8022501487113598, 'cv_recall_score': 0.31245211737057266, 'sum_top100': 683491.71}\n",
      "0.6875\n",
      "{'k_neighbors': 7, 'max_features': 70, 'n_estimators': 200, 'cv_precision_score': 0.7832483178614297, 'cv_recall_score': 0.2761865774769008, 'sum_top100': 642257.81}\n",
      "0.75\n",
      "{'k_neighbors': 9, 'max_features': 10, 'n_estimators': 200, 'cv_precision_score': 0.8389330708097761, 'cv_recall_score': 0.3010926909342348, 'sum_top100': 711182.14}\n",
      "0.8125\n",
      "{'k_neighbors': 9, 'max_features': 30, 'n_estimators': 200, 'cv_precision_score': 0.8441434472484349, 'cv_recall_score': 0.3137596112549269, 'sum_top100': 710103.46}\n",
      "0.875\n",
      "{'k_neighbors': 9, 'max_features': 50, 'n_estimators': 200, 'cv_precision_score': 0.8068572539190569, 'cv_recall_score': 0.30956508457887144, 'sum_top100': 669655.71}\n",
      "0.9375\n",
      "{'k_neighbors': 9, 'max_features': 70, 'n_estimators': 200, 'cv_precision_score': 0.7845079814465171, 'cv_recall_score': 0.29454620463921605, 'sum_top100': 671709.33}\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# Stratified cross-validation for imbalanced dataset\n",
    "skf = StratifiedKFold(n_splits = cv)\n",
    "\n",
    "def gridcv(X, y, k_neighbors, max_features, n_estimators):\n",
    "    precision_weighted_score = []\n",
    "    recall_weighted_score = []\n",
    "    total_sum = np.array([])\n",
    "    predicted_prob = np.array([])\n",
    "    true_lbl = np.array([])\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        w, Xc = X[['claim_amount']], X.drop(['claim_amount'], axis = 1)\n",
    "        \n",
    "        # train-test split\n",
    "        w_train, Xc_train, y_train = w.iloc[train_index], Xc.iloc[train_index], y[train_index]\n",
    "        w_test, Xc_test, y_test = w.iloc[test_index], Xc.iloc[test_index], y[test_index]\n",
    "        \n",
    "        # pipeline\n",
    "        pipe = Pipeline([('imputer', SimpleImputer(strategy = 'median')), \n",
    "                         ('upsampling', SMOTE(random_state = 99, k_neighbors = k_neighbors)),\n",
    "                         ('classifier',  RandomForestClassifier(random_state = 99, max_features = max_features, \n",
    "                                                                n_estimators = n_estimators, \n",
    "                                                                n_jobs = -1))])\n",
    "        pipe.fit(Xc_train, y_train)\n",
    "        calibrated_pipe = CalibratedClassifierCV(base_estimator = pipe, cv = 3, n_jobs = -1)\n",
    "        calibrated_pipe.fit(Xc_train, y_train)\n",
    "        y_pred = calibrated_pipe.predict_proba(Xc_test)[:, 1]\n",
    "        y_predt = calibrated_pipe.predict(Xc_test)\n",
    "        \n",
    "        precision_weighted_score.append(precision_score(y_test, y_predt, sample_weight = w_test.to_numpy().ravel()))\n",
    "        recall_weighted_score.append(recall_score(y_test, y_predt, sample_weight = w_test.to_numpy().ravel()))\n",
    "        total_sum = np.concatenate((w_test.to_numpy().ravel(), total_sum))\n",
    "        predicted_prob = np.concatenate((y_pred, predicted_prob))\n",
    "        true_lbl = np.concatenate((y_test, true_lbl))\n",
    "        \n",
    "    max_ind = np.argsort(-predicted_prob)[:100]\n",
    "    return {'k_neighbors': k_neighbors, 'max_features': max_features, 'n_estimators': n_estimators, \n",
    "            'cv_precision_score': np.mean(precision_weighted_score), 'cv_recall_score': np.mean(recall_weighted_score),\n",
    "           'sum_top100': np.dot(true_lbl[max_ind], total_sum[max_ind])}\n",
    "        \n",
    "# hyperparameter\n",
    "smote_knn_param = [3, 5, 7, 9]\n",
    "rf_param_nfeatures = [10, 30, 50, 70]\n",
    "i = 1\n",
    "ttl = len(smote_knn_param) * len(rf_param_nfeatures)\n",
    "\n",
    "for k in smote_knn_param:\n",
    "    for m in rf_param_nfeatures:\n",
    "        results = gridcv(X, y, k, m, 200)\n",
    "        print(results)\n",
    "        print(i/ttl)\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **<font color='blue'>Gradient boosting model with cross validation</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'k_neighbors': 3, 'number of leaves': 10, 'learning rate': 0.05, 'cv_precision_score': 0.7576120449139067, 'cv_recall_score': 0.33999376827068, 'sum_top100': 648385.4700000001}\n",
      "0.037037037037037035\n",
      "{'k_neighbors': 5, 'number of leaves': 10, 'learning rate': 0.05, 'cv_precision_score': 0.7875654193770003, 'cv_recall_score': 0.3526475787649548, 'sum_top100': 681458.95}\n",
      "0.07407407407407407\n",
      "{'k_neighbors': 7, 'number of leaves': 10, 'learning rate': 0.05, 'cv_precision_score': 0.7783172275985322, 'cv_recall_score': 0.32123263751772674, 'sum_top100': 647498.27}\n",
      "0.1111111111111111\n",
      "{'k_neighbors': 3, 'number of leaves': 10, 'learning rate': 0.1, 'cv_precision_score': 0.8517468958537935, 'cv_recall_score': 0.33659857782630276, 'sum_top100': 755360.23}\n",
      "0.14814814814814814\n",
      "{'k_neighbors': 5, 'number of leaves': 10, 'learning rate': 0.1, 'cv_precision_score': 0.8646423496415865, 'cv_recall_score': 0.3036309145812015, 'sum_top100': 743757.6799999999}\n",
      "0.18518518518518517\n",
      "{'k_neighbors': 7, 'number of leaves': 10, 'learning rate': 0.1, 'cv_precision_score': 0.8337454951009006, 'cv_recall_score': 0.32036216047926425, 'sum_top100': 728987.2}\n",
      "0.2222222222222222\n",
      "{'k_neighbors': 3, 'number of leaves': 10, 'learning rate': 0.2, 'cv_precision_score': 0.8383915259016048, 'cv_recall_score': 0.22956498850680956, 'sum_top100': 675350.6799999999}\n",
      "0.25925925925925924\n",
      "{'k_neighbors': 5, 'number of leaves': 10, 'learning rate': 0.2, 'cv_precision_score': 0.8765696581376604, 'cv_recall_score': 0.23499419448360373, 'sum_top100': 696325.52}\n",
      "0.2962962962962963\n",
      "{'k_neighbors': 7, 'number of leaves': 10, 'learning rate': 0.2, 'cv_precision_score': 0.8749518592344797, 'cv_recall_score': 0.23206797179231314, 'sum_top100': 643631.85}\n",
      "0.3333333333333333\n",
      "{'k_neighbors': 3, 'number of leaves': 20, 'learning rate': 0.05, 'cv_precision_score': 0.7838972075219864, 'cv_recall_score': 0.31149795628320304, 'sum_top100': 691277.84}\n",
      "0.37037037037037035\n",
      "{'k_neighbors': 5, 'number of leaves': 20, 'learning rate': 0.05, 'cv_precision_score': 0.8138971165356781, 'cv_recall_score': 0.35550883267015404, 'sum_top100': 739968.99}\n",
      "0.4074074074074074\n",
      "{'k_neighbors': 7, 'number of leaves': 20, 'learning rate': 0.05, 'cv_precision_score': 0.8145857255680319, 'cv_recall_score': 0.3720765569575407, 'sum_top100': 720707.19}\n",
      "0.4444444444444444\n",
      "{'k_neighbors': 3, 'number of leaves': 20, 'learning rate': 0.1, 'cv_precision_score': 0.844896746897511, 'cv_recall_score': 0.29075832203975227, 'sum_top100': 739776.3799999999}\n",
      "0.48148148148148145\n",
      "{'k_neighbors': 5, 'number of leaves': 20, 'learning rate': 0.1, 'cv_precision_score': 0.8672702647388265, 'cv_recall_score': 0.31684269402795284, 'sum_top100': 749708.05}\n",
      "0.5185185185185185\n",
      "{'k_neighbors': 7, 'number of leaves': 20, 'learning rate': 0.1, 'cv_precision_score': 0.8624040615703812, 'cv_recall_score': 0.31463432940142766, 'sum_top100': 791127.49}\n",
      "0.5555555555555556\n",
      "{'k_neighbors': 3, 'number of leaves': 20, 'learning rate': 0.2, 'cv_precision_score': 0.8681896560769609, 'cv_recall_score': 0.2270956442935935, 'sum_top100': 668702.95}\n",
      "0.5925925925925926\n",
      "{'k_neighbors': 5, 'number of leaves': 20, 'learning rate': 0.2, 'cv_precision_score': 0.8676562294246233, 'cv_recall_score': 0.25613703615293615, 'sum_top100': 682432.45}\n",
      "0.6296296296296297\n",
      "{'k_neighbors': 7, 'number of leaves': 20, 'learning rate': 0.2, 'cv_precision_score': 0.8612141253757322, 'cv_recall_score': 0.24419195562493018, 'sum_top100': 744275.98}\n",
      "0.6666666666666666\n",
      "{'k_neighbors': 3, 'number of leaves': 30, 'learning rate': 0.05, 'cv_precision_score': 0.7859950937099599, 'cv_recall_score': 0.32156541238348074, 'sum_top100': 698528.8700000001}\n",
      "0.7037037037037037\n",
      "{'k_neighbors': 5, 'number of leaves': 30, 'learning rate': 0.05, 'cv_precision_score': 0.8300235514313881, 'cv_recall_score': 0.3298076527283112, 'sum_top100': 729559.04}\n",
      "0.7407407407407407\n",
      "{'k_neighbors': 7, 'number of leaves': 30, 'learning rate': 0.05, 'cv_precision_score': 0.8363097987796216, 'cv_recall_score': 0.32740808127265775, 'sum_top100': 728911.47}\n",
      "0.7777777777777778\n",
      "{'k_neighbors': 3, 'number of leaves': 30, 'learning rate': 0.1, 'cv_precision_score': 0.8289482155757553, 'cv_recall_score': 0.2991482802879386, 'sum_top100': 748594.06}\n",
      "0.8148148148148148\n",
      "{'k_neighbors': 5, 'number of leaves': 30, 'learning rate': 0.1, 'cv_precision_score': 0.8513411279332261, 'cv_recall_score': 0.3098783933804901, 'sum_top100': 764410.73}\n",
      "0.8518518518518519\n",
      "{'k_neighbors': 7, 'number of leaves': 30, 'learning rate': 0.1, 'cv_precision_score': 0.8677934083547226, 'cv_recall_score': 0.31365694614016576, 'sum_top100': 762272.79}\n",
      "0.8888888888888888\n",
      "{'k_neighbors': 3, 'number of leaves': 30, 'learning rate': 0.2, 'cv_precision_score': 0.8682630075923387, 'cv_recall_score': 0.271822896658163, 'sum_top100': 735045.94}\n",
      "0.9259259259259259\n",
      "{'k_neighbors': 5, 'number of leaves': 30, 'learning rate': 0.2, 'cv_precision_score': 0.8787914412883815, 'cv_recall_score': 0.2799156848151363, 'sum_top100': 717341.11}\n",
      "0.9629629629629629\n",
      "{'k_neighbors': 7, 'number of leaves': 30, 'learning rate': 0.2, 'cv_precision_score': 0.8722334090995518, 'cv_recall_score': 0.2620065651602176, 'sum_top100': 716289.6300000001}\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# Stratified cross-validation for imbalanced dataset\n",
    "skf = StratifiedKFold(n_splits = cv)\n",
    "\n",
    "def gridcv_gb(X, y, k, nl, lr):\n",
    "    precision_weighted_score = []\n",
    "    recall_weighted_score = []\n",
    "    total_sum = np.array([])\n",
    "    predicted_prob = np.array([])\n",
    "    true_lbl = np.array([])\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        w, Xc = X[['claim_amount']], X.drop(['claim_amount'], axis = 1)\n",
    "        \n",
    "        # train-test split\n",
    "        w_train, Xc_train, y_train = w.iloc[train_index], Xc.iloc[train_index], y[train_index]\n",
    "        w_test, Xc_test, y_test = w.iloc[test_index], Xc.iloc[test_index], y[test_index]\n",
    "        \n",
    "        # pipeline\n",
    "        pipe = Pipeline([('imputer', SimpleImputer(strategy = 'median')), \n",
    "                         ('upsampling', SMOTE(random_state = 99, k_neighbors = k)),\n",
    "                         ('classifier',  LGBMClassifier(random_state = 99, num_leaves = nl, learning_rate = lr, max_depth = 7))])\n",
    "        pipe.fit(Xc_train, y_train)\n",
    "        calibrated_pipe = CalibratedClassifierCV(base_estimator = pipe, cv = 3, n_jobs = -1)\n",
    "        calibrated_pipe.fit(Xc_train, y_train)\n",
    "        y_pred = calibrated_pipe.predict_proba(Xc_test)[:, 1]\n",
    "        y_predt = calibrated_pipe.predict(Xc_test)\n",
    "        \n",
    "        precision_weighted_score.append(precision_score(y_test, y_predt, sample_weight = w_test.to_numpy().ravel()))\n",
    "        recall_weighted_score.append(recall_score(y_test, y_predt, sample_weight = w_test.to_numpy().ravel()))\n",
    "        total_sum = np.concatenate((w_test.to_numpy().ravel(), total_sum))\n",
    "        predicted_prob = np.concatenate((y_pred, predicted_prob))\n",
    "        true_lbl = np.concatenate((y_test, true_lbl))\n",
    "        \n",
    "    max_ind = np.argsort(-predicted_prob)[:100]\n",
    "    return {'k_neighbors': k, 'number of leaves': nl, 'learning rate': lr, \n",
    "            'cv_precision_score': np.mean(precision_weighted_score), 'cv_recall_score': np.mean(recall_weighted_score),\n",
    "           'sum_top100': np.dot(true_lbl[max_ind], total_sum[max_ind])}\n",
    "        \n",
    "# hyperparameter\n",
    "num_leaves = [10, 20, 30]\n",
    "learning_rate = [0.05, 0.1, 0.2]\n",
    "knn = [3, 5, 7]\n",
    "\n",
    "i = 1\n",
    "ttl = len(num_leaves) * len(learning_rate) * len(knn)\n",
    "\n",
    "for nl in num_leaves:\n",
    "    for lr in learning_rate:\n",
    "        for k in knn:\n",
    "            results = gridcv_gb(X, y, k, nl, lr)\n",
    "            print(results)\n",
    "            print(i/ttl)\n",
    "            i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **<font color='blue'>Prediction</font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **<font color='blue'>Random forest</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Align features\n",
    "X_train = X.drop(['claim_amount'], axis = 1)\n",
    "X_test = X_test.reindex(columns = X_train.columns, fill_value = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('imputer',\n",
       "                 SimpleImputer(add_indicator=True, strategy='median')),\n",
       "                ('upsampling', SMOTE(k_neighbors=3, random_state=99)),\n",
       "                ('classifier',\n",
       "                 RandomForestClassifier(max_features=30, n_estimators=500,\n",
       "                                        n_jobs=-1, random_state=99))])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pipeline\n",
    "pipe = Pipeline([('imputer', SimpleImputer(strategy = 'median', add_indicator = True)), \n",
    "                ('upsampling', SMOTE(random_state = 99, k_neighbors = 3)),\n",
    "                ('classifier',  RandomForestClassifier(random_state = 99, max_features = 30, \n",
    "                                                        n_estimators = 500, \n",
    "                                                        n_jobs = -1))])\n",
    "pipe.fit(X_train, y)\n",
    "calibrated_pipe = CalibratedClassifierCV(base_estimator = pipe, cv = 3, n_jobs = -1)\n",
    "calibrated_pipe.fit(X_train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make prediction\n",
    "y_pred = calibrated_pipe.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe which contains the results\n",
    "pred = pd.DataFrame()\n",
    "pred['ID'] = data_test['claim_id']\n",
    "pred['PROB'] = y_pred[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export data\n",
    "pred.to_csv(path + r'\\results_randomforest_v2.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **<font color='blue'>Light GBM</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CalibratedClassifierCV(base_estimator=Pipeline(steps=[('imputer',\n",
       "                                                       SimpleImputer(add_indicator=True,\n",
       "                                                                     strategy='median')),\n",
       "                                                      ('upsampling',\n",
       "                                                       SMOTE(k_neighbors=7,\n",
       "                                                             random_state=99)),\n",
       "                                                      ('classifier',\n",
       "                                                       LGBMClassifier(max_depth=7,\n",
       "                                                                      num_leaves=20,\n",
       "                                                                      random_state=99))]),\n",
       "                       cv=3, n_jobs=-1)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pipeline\n",
    "pipe2 = Pipeline([('imputer', SimpleImputer(strategy = 'median', add_indicator = True)), \n",
    "                ('upsampling', SMOTE(random_state = 99, k_neighbors = 7)),\n",
    "                ('classifier',   LGBMClassifier(random_state = 99, num_leaves = 20, learning_rate = 0.1, max_depth = 7))])\n",
    "pipe2.fit(X_train, y)\n",
    "calibrated_pipe2 = CalibratedClassifierCV(base_estimator = pipe2, cv = 3, n_jobs = -1)\n",
    "calibrated_pipe2.fit(X_train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make prediction\n",
    "y_pred = calibrated_pipe2.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe which contains the results\n",
    "pred = pd.DataFrame()\n",
    "pred['ID'] = data_test['claim_id']\n",
    "pred['PROB'] = y_pred[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export data\n",
    "pred.to_csv(path + r'\\results_lightgbm_v2.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>PROB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>840</th>\n",
       "      <td>66309</td>\n",
       "      <td>0.958200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2406</th>\n",
       "      <td>67875</td>\n",
       "      <td>0.652193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2409</th>\n",
       "      <td>67878</td>\n",
       "      <td>0.850049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3858</th>\n",
       "      <td>69327</td>\n",
       "      <td>0.813430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4113</th>\n",
       "      <td>69582</td>\n",
       "      <td>0.897359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4345</th>\n",
       "      <td>69814</td>\n",
       "      <td>0.955568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4519</th>\n",
       "      <td>69988</td>\n",
       "      <td>0.953728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4946</th>\n",
       "      <td>70415</td>\n",
       "      <td>0.856759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5423</th>\n",
       "      <td>70892</td>\n",
       "      <td>0.935269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6904</th>\n",
       "      <td>72374</td>\n",
       "      <td>0.960168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6906</th>\n",
       "      <td>72376</td>\n",
       "      <td>0.819196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8053</th>\n",
       "      <td>73523</td>\n",
       "      <td>0.745724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8523</th>\n",
       "      <td>73993</td>\n",
       "      <td>0.540342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8740</th>\n",
       "      <td>74210</td>\n",
       "      <td>0.914630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9661</th>\n",
       "      <td>75131</td>\n",
       "      <td>0.505241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12692</th>\n",
       "      <td>78164</td>\n",
       "      <td>0.850798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13082</th>\n",
       "      <td>78554</td>\n",
       "      <td>0.889426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14124</th>\n",
       "      <td>79596</td>\n",
       "      <td>0.645068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14563</th>\n",
       "      <td>80035</td>\n",
       "      <td>0.840668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15448</th>\n",
       "      <td>80920</td>\n",
       "      <td>0.842293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15644</th>\n",
       "      <td>81116</td>\n",
       "      <td>0.882197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17034</th>\n",
       "      <td>82506</td>\n",
       "      <td>0.954834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17324</th>\n",
       "      <td>82796</td>\n",
       "      <td>0.953067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18156</th>\n",
       "      <td>83628</td>\n",
       "      <td>0.958757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18424</th>\n",
       "      <td>83896</td>\n",
       "      <td>0.839569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18949</th>\n",
       "      <td>84421</td>\n",
       "      <td>0.673621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18953</th>\n",
       "      <td>84425</td>\n",
       "      <td>0.879353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19398</th>\n",
       "      <td>84870</td>\n",
       "      <td>0.908307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19433</th>\n",
       "      <td>84905</td>\n",
       "      <td>0.754794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19602</th>\n",
       "      <td>85074</td>\n",
       "      <td>0.746737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20945</th>\n",
       "      <td>86417</td>\n",
       "      <td>0.514958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21530</th>\n",
       "      <td>87002</td>\n",
       "      <td>0.912925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21747</th>\n",
       "      <td>87219</td>\n",
       "      <td>0.792759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23781</th>\n",
       "      <td>89253</td>\n",
       "      <td>0.749273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24984</th>\n",
       "      <td>90456</td>\n",
       "      <td>0.894101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25526</th>\n",
       "      <td>90998</td>\n",
       "      <td>0.744111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25997</th>\n",
       "      <td>91469</td>\n",
       "      <td>0.936097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27446</th>\n",
       "      <td>92918</td>\n",
       "      <td>0.583280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27448</th>\n",
       "      <td>92920</td>\n",
       "      <td>0.866231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27896</th>\n",
       "      <td>93368</td>\n",
       "      <td>0.944410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27961</th>\n",
       "      <td>93433</td>\n",
       "      <td>0.765268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29594</th>\n",
       "      <td>95066</td>\n",
       "      <td>0.742799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29942</th>\n",
       "      <td>95414</td>\n",
       "      <td>0.933606</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID      PROB\n",
       "840    66309  0.958200\n",
       "2406   67875  0.652193\n",
       "2409   67878  0.850049\n",
       "3858   69327  0.813430\n",
       "4113   69582  0.897359\n",
       "4345   69814  0.955568\n",
       "4519   69988  0.953728\n",
       "4946   70415  0.856759\n",
       "5423   70892  0.935269\n",
       "6904   72374  0.960168\n",
       "6906   72376  0.819196\n",
       "8053   73523  0.745724\n",
       "8523   73993  0.540342\n",
       "8740   74210  0.914630\n",
       "9661   75131  0.505241\n",
       "12692  78164  0.850798\n",
       "13082  78554  0.889426\n",
       "14124  79596  0.645068\n",
       "14563  80035  0.840668\n",
       "15448  80920  0.842293\n",
       "15644  81116  0.882197\n",
       "17034  82506  0.954834\n",
       "17324  82796  0.953067\n",
       "18156  83628  0.958757\n",
       "18424  83896  0.839569\n",
       "18949  84421  0.673621\n",
       "18953  84425  0.879353\n",
       "19398  84870  0.908307\n",
       "19433  84905  0.754794\n",
       "19602  85074  0.746737\n",
       "20945  86417  0.514958\n",
       "21530  87002  0.912925\n",
       "21747  87219  0.792759\n",
       "23781  89253  0.749273\n",
       "24984  90456  0.894101\n",
       "25526  90998  0.744111\n",
       "25997  91469  0.936097\n",
       "27446  92918  0.583280\n",
       "27448  92920  0.866231\n",
       "27896  93368  0.944410\n",
       "27961  93433  0.765268\n",
       "29594  95066  0.742799\n",
       "29942  95414  0.933606"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[pred['PROB']>0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
